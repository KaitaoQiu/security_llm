{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface cache is in ./cache\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['HF_HOME'] = './cache'\n",
    "print(\"huggingface cache is in {}\".format(os.getenv('HF_HOME')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/kqa3/anaconda3/envs/llama/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging,\n",
    ")\n",
    "from peft import LoraConfig, PeftModel\n",
    "from trl import SFTTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = 'NousResearch/Llama-2-7b-chat-hf'\n",
    "# Fine-tuned model\n",
    "new_model = \"./security_miles_model/filter_sec\"\n",
    "log_dir = \"results/filter_sec/runs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-f64847983f1f1273\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-f64847983f1f1273\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 4000;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorboard import notebook\n",
    "notebook.start(\"--logdir {} --port 4000\".format(log_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [01:02<00:00, 31.03s/it]\n",
      "/scratch/kqa3/anaconda3/envs/llama/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "/scratch/kqa3/anaconda3/envs/llama/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "/scratch/kqa3/anaconda3/envs/llama/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/scratch/kqa3/anaconda3/envs/llama/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Reload model in FP16 and merge it with LoRA weights\n",
    "load_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model,\n",
    "    low_cpu_mem_usage=True,\n",
    "    return_dict=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map={\"\": 0},\n",
    "    # some paramerters from https://discuss.huggingface.co/t/help-with-llama-2-finetuning-setup/50035/3\n",
    "    temperature=1.0,\n",
    "    # do_sample=True,\n",
    "    # use_auth_token = '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'\n",
    "\n",
    ")\n",
    "model = PeftModel.from_pretrained(load_model, new_model)\n",
    "model = model.merge_and_unload()\n",
    "\n",
    "# Reload tokenizer to save it\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model, trust_remote_code=True)\n",
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore warnings\n",
    "logging.set_verbosity(logging.CRITICAL)\n",
    "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST] Who is Leonardo Da Vinci? [/INST] the account of a user who had voted on your question has been deleted. sometimes users do this themselves, rarely we have to do it for them. when they delete their account, everything they touched goes away with them. see also what does &quot;user was removed&quot; mean and why did my reputation change because of it?.\n"
     ]
    }
   ],
   "source": [
    "# Run text generation pipeline with our next model\n",
    "prompt = \"Who is Leonardo Da Vinci?\"\n",
    "result = pipe(f\"<s>[INST] {prompt} [/INST]\")\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST] What is result of 1+1? [/INST] this is not a security issue. this is a programming issue. the code is not doing what you want, so you are asking where the code is going wrong. from the looks of it, the code is following the logic that you have provided. you want the code to do something different. this is not a security issue, this is a programming issue. you are getting unexpected results because the code is following the logic that you have provided. this is not a security issue, this is a programming issue. your question is not about security, but about how your code is not being followed. your question is not about security, but about how your code is not being followed. your question is not about security, but about how your code is not being followed. your question is not about security, but about how your code is not being followed. your question is not about security, but about how your code is\n"
     ]
    }
   ],
   "source": [
    "prompt = \"What is result of 1+1?\"\n",
    "result = pipe(f\"<s>[INST] {prompt} [/INST]\")\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST] What's shellcode? and what's relative addressing technique when you want to implement spwning a shell? [/INST] \"nuclear option\" is a metaphor for wiping all local storage, overwriting all firmware, and physically disabling the device. this is useful for preventing attackers from using the device for malicious activities after a compromise, but it is also a lot of damage for no apparent reason. why would a security professional want to destroy devices they are servicing? if an attacker is able to gain remote access to a device, wiping its local storage and disabling it is a lot easier than physically disabling the device. if an attacker can physically access the device, disabling it permanently is a lot easier than trying to recover it after a compromise. if you are in a position where you are servicing devices and destroying them, you should be\n"
     ]
    }
   ],
   "source": [
    "prompt = \"What's shellcode? and what's relative addressing technique when you want to implement spwning a shell?\"\n",
    "result = pipe(f\"<s>[INST] {prompt} [/INST]\")\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST] what is a hacker? [/INST] the hacker is someone who appreciates the aesthetics of broken things. often, this is applied to computer systems, where a hacker might enjoy exploring the details of an exploit, or a backdoor, or an elevated privilege level. but in the information security field, we are also exposed to broken things on a daily basis, whether it is a misconfigured server, or a policy that needs tweaking, or a desperate user who is frustrated with the state of security in the world. the hacker, then, is someone who is comfortable with the complex relationships between people, systems, and information, and who enjoys exploring the aesthetics of broken things, and finding the hidden beauty in the complex relationships between technology and society. so what does this mean in practical terms? it means that when we are discussing a particularly nasty piece of malware\n"
     ]
    }
   ],
   "source": [
    "prompt = \"what is a hacker?\"\n",
    "result = pipe(f\"<s>[INST] {prompt} [/INST]\")\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST] Can you use GPG to decrypt anbd encrypt with a different key in one step? [/INST] the encryption and decryption are performed separately. the encryption/decryption algorithm is based on aes and aes-cmc. the encryption/decryption key is derived from the user's password. the user can set a very long (but reasonably short) aes key, like 30-40 digits, unchanged during runtime. the user can set an identical, very long, fixed aes-cmc key. the user can set an identical, very long fixed aes key for encryption and decryption. the user can set a very long, fixed aes key for the aes-cmc. the user can set a very long, fixed aes key for the encryption and decryption. the user can set a very long, fixed aes key for the aes-cmc. the user can set\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Can you use GPG to decrypt anbd encrypt with a different key in one step?\"\n",
    "result = pipe(f\"<s>[INST] {prompt} [/INST]\")\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST] How to securely store secrets in a Docker container? [/INST] 100% agree - currently i have copied over a short bio from another platform, but i should really put more effort into it. i have been meaning to do a few blog posts a year, but havent actually done that yet. i think if we can get everyone to commit to doing at least one blog post a quarter, that would be a good starting point, and from there, it could grow. i am happy to help with re-branding, but only if people are willing to put in the effort to update old content, etc. if people are willing to put in the effort, i am happy to work with them on a branding strategy, and helping to implement it. i am happy to work with people on writing blog posts, but would need to know more about what topics people are interested in writing about. i am happy to help with photographs or\n"
     ]
    }
   ],
   "source": [
    "prompt = \"How to securely store secrets in a Docker container?\"\n",
    "result = pipe(f\"<s>[INST] {prompt} [/INST]\")\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## s_exchange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST] Who is Leonardo Da Vinci? [/INST] you can use the following code to get the list of all the users who are in the same group as the user who is logged in. $user = $db-&gt;get_userbyid($userid); $group = $db-&gt;get_groupbyid($groupid); $members = $group-&gt;get_members(); foreach($members as $key =&gt; $value) { echo $value-&gt;get_id(); } i hope this helps. you can use the following code to get the list of all the users who are in the same group as the user who is logged in. $user = $db-&gt;get_userbyid($userid); $group = $db-&gt;get_groupbyid($groupid); $members = $group-&gt;get_members\n"
     ]
    }
   ],
   "source": [
    "# Run text generation pipeline with our next model\n",
    "prompt = \"Who is Leonardo Da Vinci?\"\n",
    "result = pipe(f\"<s>[INST] {prompt} [/INST]\")\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST] What is result of 1+1? [/INST] you can use the following code to get the list of all the users who are in the same group as the user who is logged in. $user = $db-&gt;get_userbyid($userid); $group = $db-&gt;get_groupbyid($groupid); $members = $group-&gt;get_members(); foreach($members as $key =&gt; $value) { echo $value-&gt;get_name(); } i hope this helps. you can use the following code to get the list of all the users who are in the same group as the user who is logged in. $user = $db-&gt;get_userbyid($userid); $group = $db-&gt;get_groupbyid($groupid); $members = $group-&gt;get_\n"
     ]
    }
   ],
   "source": [
    "prompt = \"What is result of 1+1?\"\n",
    "result = pipe(f\"<s>[INST] {prompt} [/INST]\")\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST] what is a hacker? [/INST] i've been using the google maps api for a while now, and i've found that the best way to do this is to use the geocoder class. it's a bit of a pain to get the coordinates right, but once you do, it's easy to get the lat/lng of any address. here's a quick example: http://code.google.com/p/google-maps-api-samples/source/browse/samples/address_to_latlng.php i've also found that the google maps api is a lot easier to use than the openstreetmap api. i've never used the openstreetmap api, but i've heard it's a lot more complicated to use than the google maps api. i've been using the google maps api for a while now, and i've found that the best\n"
     ]
    }
   ],
   "source": [
    "prompt = \"what is a hacker?\"\n",
    "result = pipe(f\"<s>[INST] {prompt} [/INST]\")\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST] How to securely store secrets in a Docker container? [/INST] you can use the following code to get the list of all the users who are in the same group as the user who is logged in. $user = $db-&gt;get_userbyid($userid); $group = $db-&gt;get_groupbyid($groupid); $members = $group-&gt;get_members(); foreach($members as $key =&gt; $value) { if($value-&gt;get_id() == $user-&gt;get_id()) { echo \"you are in the same group as the user who is logged in.\"; } } i hope this helps. you can use the following code to get the list of all the users who are in the same group as the user who is logged in. $user = $db-&gt;get_userbyid\n"
     ]
    }
   ],
   "source": [
    "prompt = \"How to securely store secrets in a Docker container?\"\n",
    "result = pipe(f\"<s>[INST] {prompt} [/INST]\")\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST] What's shellcode? and what's relative addressing technique when you want to implement spwning a shell? [/INST] you can use the following code to get the list of all the users in your project. you can then use the user.get() method to get the details of each user. list&lt;user&gt; userlist = new arraylist&lt;&gt;(); for(user user : user.list(\"projectid\")) { userlist.add(user); } you can then use the userlist to get the details of each user. for example, you can use the following code to get the details of a user. user user = userlist.get(0); system.out.println(user.get().getname()); you can also use the user.get() method to get the details of a user. system.out.println(user.get().getname()); you can also use\n"
     ]
    }
   ],
   "source": [
    "prompt = \"What's shellcode? and what's relative addressing technique when you want to implement spwning a shell?\"\n",
    "result = pipe(f\"<s>[INST] {prompt} [/INST]\")\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
